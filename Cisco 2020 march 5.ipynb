{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split -- takes an X (inputs/examples) and y (outputs/answers)\n",
    "#  returns X_train, X_test, y_train, y_test\n",
    "#  train with X_train and y_train\n",
    "#  test with X_test and y_test\n",
    "#   we can check -- are the results (y_pred) the same as y_test?\n",
    "#   if not the same, how close?\n",
    "\n",
    "# cross_val_score -- function that does the same sort of testing\n",
    "#  as train_test_split, but we don't have to do as much.  We can\n",
    "#  swap out the algorithm for a different testing strategy\n",
    "\n",
    "# the default strategy is StratifiedKFold, which means: create n\n",
    "#  groups, each group *MUST* have at least one rep from each class\n",
    "#  (category)\n",
    "\n",
    "# another strategy is LeaveOneOut -- train with all but one\n",
    "#  of the data points, and test with one data point.  With n\n",
    "#  data points, we'll do n iterations, each giving 0/1 for \n",
    "#  successful prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    5.000000\n",
       "mean     0.973333\n",
       "std      0.027889\n",
       "min      0.933333\n",
       "25%      0.966667\n",
       "50%      0.966667\n",
       "75%      1.000000\n",
       "max      1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = Series(iris.target)\n",
    "\n",
    "model = KNeighborsClassifier()  # default: k=5\n",
    "\n",
    "results = cross_val_score(model, X, y, cv=5)  # divide into 5 parts\n",
    "Series(results).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    5.000000\n",
       "mean     0.973333\n",
       "std      0.027889\n",
       "min      0.933333\n",
       "25%      0.966667\n",
       "50%      0.966667\n",
       "75%      1.000000\n",
       "max      1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, LeaveOneOut\n",
    "\n",
    "strategy = StratifiedKFold()\n",
    "\n",
    "iris = load_iris()\n",
    "X = DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = Series(iris.target)\n",
    "\n",
    "model = KNeighborsClassifier()  # default: k=5\n",
    "\n",
    "results = cross_val_score(model, X, y, cv=strategy)  # divide into 5 parts\n",
    "Series(results).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    3.000000\n",
       "mean     0.966667\n",
       "std      0.011547\n",
       "min      0.960000\n",
       "25%      0.960000\n",
       "50%      0.960000\n",
       "75%      0.970000\n",
       "max      0.980000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, LeaveOneOut\n",
    "\n",
    "strategy = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "iris = load_iris()\n",
    "X = DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = Series(iris.target)\n",
    "\n",
    "model = KNeighborsClassifier()  \n",
    "\n",
    "results = cross_val_score(model, X, y, cv=strategy)  # divide into 5 parts\n",
    "Series(results).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    150.000000\n",
       "mean       0.966667\n",
       "std        0.180107\n",
       "min        0.000000\n",
       "25%        1.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, LeaveOneOut\n",
    "\n",
    "strategy = LeaveOneOut()\n",
    "\n",
    "iris = load_iris()\n",
    "X = DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = Series(iris.target)\n",
    "\n",
    "# model = KNeighborsClassifier(n_neighbors=11)\n",
    "model = KNeighborsClassifier()  \n",
    "\n",
    "results = cross_val_score(model, X, y, cv=strategy)  # divide into 5 parts\n",
    "Series(results).describe()\n",
    "\n",
    "# Use a \"for\" loop to iterate over all k values from 1 to 23\n",
    "# Use cross_val_score and LeaveOneOut to identify the best\n",
    "# value of k (highest mean, lowest std, lowest k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 5 7 9 11 13 15 17 19 21 23 "
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, LeaveOneOut\n",
    "\n",
    "strategy = LeaveOneOut()\n",
    "\n",
    "iris = load_iris()\n",
    "X = DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = Series(iris.target)\n",
    "\n",
    "all_results = []\n",
    "for k in range(1, 24, 2):\n",
    "    print(k, end=' ')\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    results = cross_val_score(model, X, y, cv=strategy)  # divide into 5 parts\n",
    "    all_results.append({'k':k, \n",
    "                        'mean':results.mean(), \n",
    "                        'std':results.std()})\n",
    "\n",
    "# Use a \"for\" loop to iterate over all k values from 1 to 23\n",
    "# Use cross_val_score and LeaveOneOut to identify the best\n",
    "# value of k (highest mean, lowest std, lowest k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.195959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.195959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.179505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.179505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.179505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.161107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.179505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.161107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.161107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.179505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean       std\n",
       "k                     \n",
       "1   0.960000  0.195959\n",
       "3   0.960000  0.195959\n",
       "5   0.966667  0.179505\n",
       "7   0.966667  0.179505\n",
       "9   0.966667  0.179505\n",
       "11  0.973333  0.161107\n",
       "13  0.966667  0.179505\n",
       "15  0.973333  0.161107\n",
       "17  0.973333  0.161107\n",
       "19  0.980000  0.140000\n",
       "21  0.980000  0.140000\n",
       "23  0.966667  0.179505"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame(all_results).set_index('k')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12e205f90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['mean'].plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, KFold, StratifiedKFold, LeaveOneOut\n",
    "\n",
    "strategy = StratifiedKFold()\n",
    "\n",
    "iris = load_iris()\n",
    "X = DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = Series(iris.target)\n",
    "\n",
    "model = KNeighborsClassifier()  \n",
    "\n",
    "results = cross_validate(model, X, y, cv=strategy)  # divide into 5 parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01580596, 0.01308513, 0.01501799, 0.05276299, 0.00981498]),\n",
       " 'score_time': array([0.01788592, 0.02835894, 0.05560994, 0.02706718, 0.01465082]),\n",
       " 'test_score': array([0.96666667, 1.        , 0.93333333, 0.96666667, 1.        ])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015806</td>\n",
       "      <td>0.017886</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013085</td>\n",
       "      <td>0.028359</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015018</td>\n",
       "      <td>0.055610</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052763</td>\n",
       "      <td>0.027067</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009815</td>\n",
       "      <td>0.014651</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  0.015806    0.017886    0.966667\n",
       "1  0.013085    0.028359    1.000000\n",
       "2  0.015018    0.055610    0.933333\n",
       "3  0.052763    0.027067    0.966667\n",
       "4  0.009815    0.014651    1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008005</td>\n",
       "      <td>0.018493</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.011457</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.012367</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008073</td>\n",
       "      <td>0.012160</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006127</td>\n",
       "      <td>0.009114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.008005    0.018493    0.966667     0.966667\n",
       "1  0.007895    0.011457    1.000000     0.966667\n",
       "2  0.010417    0.012367    0.933333     0.975000\n",
       "3  0.008073    0.012160    0.966667     0.975000\n",
       "4  0.006127    0.009114    1.000000     0.966667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, KFold, StratifiedKFold, LeaveOneOut\n",
    "\n",
    "strategy = StratifiedKFold()\n",
    "\n",
    "iris = load_iris()\n",
    "X = DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = Series(iris.target)\n",
    "\n",
    "model = KNeighborsClassifier()  \n",
    "\n",
    "results = cross_validate(model, X, y, cv=strategy, \n",
    "                         return_train_score=True)  # divide into 5 parts\n",
    "DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametric model -- short and simple, usually using a \n",
    "#  mathematical equation to decide what's in each class.\n",
    "\n",
    "# works well with regular, easily described data.\n",
    "\n",
    "# LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "# non-parametric model -- can be complex and use extra memory\n",
    "#  or time.  \n",
    "\n",
    "# works well with all sorts of data, including when it's not\n",
    "# regularly distributed\n",
    "\n",
    "# KNeighborsClassifier is non-parametric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024637</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023267</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015062</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015072</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009636</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.024637    0.004684    1.000000     0.950000\n",
       "1  0.023267    0.018279    0.966667     0.966667\n",
       "2  0.015062    0.004546    0.933333     0.966667\n",
       "3  0.015072    0.003305    0.900000     0.975000\n",
       "4  0.009636    0.002806    1.000000     0.958333"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, KFold, StratifiedKFold, LeaveOneOut\n",
    "\n",
    "strategy = StratifiedKFold()\n",
    "\n",
    "iris = load_iris()\n",
    "X = DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = Series(iris.target)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')  \n",
    "\n",
    "results = cross_validate(model, X, y, cv=strategy, \n",
    "                         return_train_score=True) \n",
    "DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.017535\n",
       "score_time     0.006724\n",
       "test_score     0.960000\n",
       "train_score    0.963333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(results).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.014668\n",
       "score_time     0.017899\n",
       "test_score     0.966667\n",
       "train_score    0.975000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, KFold, StratifiedKFold, LeaveOneOut\n",
    "\n",
    "strategy = StratifiedKFold()\n",
    "\n",
    "iris = load_iris()\n",
    "X = DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = Series(iris.target)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=17)\n",
    "\n",
    "results = cross_validate(model, X, y, cv=strategy, \n",
    "                         return_train_score=True) \n",
    "DataFrame(results).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Logistic Regression to make iris predictions\n",
    "# How does it do?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier: mean 0.9733333333333334, std 0.02494438257849294\n",
      "LogisticRegression  : mean 0.9600000000000002, std 0.038873012632301994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, KFold, StratifiedKFold, LeaveOneOut\n",
    "\n",
    "strategy = StratifiedKFold()\n",
    "\n",
    "iris = load_iris()\n",
    "X = DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = Series(iris.target)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "lr = LogisticRegression(solver='liblinear')  \n",
    "\n",
    "for model in [knn, lr]:\n",
    "    results = cross_val_score(model, X, y, cv=strategy)\n",
    "    print(f'{model.__class__.__name__:20}: mean {results.mean()}, std {results.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CART -- classification and regression trees\n",
    "#   aka \"decision trees\"\n",
    "\n",
    "# when we train (fit) a decision-tree model, \n",
    "# the model looks at all variables and values\n",
    "\n",
    "# it finds the best split between Y/N (or </>) for the\n",
    "# current data\n",
    "\n",
    "# non-parametrics\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM -- simple vector machines\n",
    "# very popular nowadays, especially with relative few data points\n",
    "\n",
    "from sklearn.svm import SVC   # SVM classifier\n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Copy the test harness that I created above with\n",
    "# logistic regression and KNeighborsClassifier.  Add\n",
    "# DecisionTree Classifier and SVC to those.\n",
    "\n",
    "# (If you encounter problems/warnings/errors, let me know -- \n",
    "# I'll help you to fix them.)\n",
    "\n",
    "# Question: Which of these models has the highest mean \n",
    "# prediction accuracy, with the lowest standard deviation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier   : mean 0.9733, std 0.025\n",
      "LogisticRegression     : mean  0.96, std 0.039\n",
      "DecisionTreeClassifier : mean 0.9667, std 0.037\n",
      "SVC                    : mean 0.9667, std 0.021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, KFold, StratifiedKFold, LeaveOneOut\n",
    "\n",
    "strategy = StratifiedKFold()\n",
    "\n",
    "iris = load_iris()\n",
    "X = DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = Series(iris.target)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "lr = LogisticRegression(solver='liblinear')  \n",
    "dtc = DecisionTreeClassifier()\n",
    "svc = SVC()\n",
    "\n",
    "for model in [knn, lr, dtc, svc]:\n",
    "    results = cross_val_score(model, X, y, cv=strategy)\n",
    "    print(f'{model.__class__.__name__:23}: mean {results.mean():5.4}, std {results.std():5.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, KFold, StratifiedKFold, LeaveOneOut\n",
    "\n",
    "strategy = StratifiedKFold()\n",
    "\n",
    "iris = load_iris()\n",
    "X = DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = Series(iris.target)\n",
    "\n",
    "knns = []\n",
    "for k in range(1, 24, 2):\n",
    "    knns.append(KNeighborsClassifier(n_neighbors=k))\n",
    "lr = LogisticRegression(solver='liblinear')  \n",
    "dtc = DecisionTreeClassifier()\n",
    "svc = SVC()\n",
    "\n",
    "all_results = []\n",
    "for model in [*knns, lr, dtc, svc]:\n",
    "    results = cross_val_score(model, X, y, cv=strategy)\n",
    "    all_results.append({'model': model.__class__.__name__,\n",
    "                        'mean': results.mean(),\n",
    "                        'std': results.std()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12ebe7510>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQXElEQVR4nO3cfbBcdX3H8feXBKjIk5rLUxK4WENt+qDSO4EpzkDHhwbsJFaYDnGsSin5o1KYyljT0gEnfULasTNtURtHpVCBBlrtbQmGIiAzttBcBCJJiF7CQxItXJDCVKgQ/PaPc8Ism3vv7t2zm+T+eL9mdnLO7/z2e77Zu/dzz549u5GZSJJmvwP2dQOSpP4w0CWpEAa6JBXCQJekQhjoklQIA12SCjF3X+143rx5OTw8vK92L0mz0r333vtUZg5Ntm2fBfrw8DBjY2P7aveSNCtFxGNTbet4yiUivhQRT0bEg1Nsj4j464gYj4iNEXFyk2YlSb3p5hz61cDSabafCSyqbyuBzzVvS5I0Ux0DPTPvAn44zZTlwDVZuRs4MiKO7VeDkqTu9OMql/nA9pb1HfWYJGkv2quXLUbEyogYi4ixiYmJvblrSSpePwJ9J7CwZX1BPbaHzFyTmSOZOTI0NOlVN5KkHvUj0EeBD9dXu5wKPJuZP+hDXUnSDHS8Dj0irgfOAOZFxA7gcuBAgMz8PLAOOAsYB54HzhtUs5KkqXUM9Mxc0WF7Ah/rW0d6xfCqm7ue++gV7xtgJ92Zbf1KpdlnnxQtxWwMMXuWyuSXc0lSIV4zR+ge4Wkyg3peDPL5Nht7VmXQj/F+F+g+qaSy7A9/gGZae7bylIskFWK/O0KXpH1ttp4p8AhdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5Jhegq0CNiaURsjYjxiFg1yfbjI+KOiLgvIjZGxFn9b1WSNJ2OgR4Rc4CrgDOBxcCKiFjcNu2PgLWZ+Q7gXOCz/W5UkjS9bo7QlwDjmbktM18EbgCWt81J4PB6+Qjg+/1rUZLUjW4CfT6wvWV9Rz3W6lPAhyJiB7AO+N3JCkXEyogYi4ixiYmJHtqVJE2lX2+KrgCuzswFwFnAtRGxR+3MXJOZI5k5MjQ01KddS5Kgu0DfCSxsWV9Qj7U6H1gLkJn/CfwUMK8fDUqSutNNoG8AFkXEiRFxENWbnqNtcx4H3gUQET9LFeieU5GkvahjoGfmLuBCYD2whepqlk0RsToiltXTLgEuiIgHgOuBj2ZmDqppSdKe5nYzKTPXUb3Z2Tp2WcvyZuC0/rYmSZoJPykqSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmF6CrQI2JpRGyNiPGIWDXFnN+IiM0RsSkirutvm5KkTuZ2mhARc4CrgPcAO4ANETGamZtb5iwC/gA4LTOfiYijBtWwJGly3RyhLwHGM3NbZr4I3AAsb5tzAXBVZj4DkJlP9rdNSVIn3QT6fGB7y/qOeqzVScBJEfGtiLg7IpZOVigiVkbEWESMTUxM9NaxJGlS/XpTdC6wCDgDWAF8ISKObJ+UmWsycyQzR4aGhvq0a0kSdBfoO4GFLesL6rFWO4DRzHwpMx8BvksV8JKkvaSbQN8ALIqIEyPiIOBcYLRtzteojs6JiHlUp2C29bFPSVIHHQM9M3cBFwLrgS3A2szcFBGrI2JZPW098HREbAbuAD6RmU8PqmlJ0p46XrYIkJnrgHVtY5e1LCfw8fomSdoH/KSoJBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVoqtAj4ilEbE1IsYjYtU0886OiIyIkf61KEnqRsdAj4g5wFXAmcBiYEVELJ5k3mHAxcA9/W5SktRZN0foS4DxzNyWmS8CNwDLJ5n3x8Cngf/rY3+SpC51E+jzge0t6zvqsVdExMnAwsy8uY+9SZJmoPGbohFxAPAZ4JIu5q6MiLGIGJuYmGi6a0lSi24CfSewsGV9QT2222HAzwN3RsSjwKnA6GRvjGbmmswcycyRoaGh3ruWJO2hm0DfACyKiBMj4iDgXGB098bMfDYz52XmcGYOA3cDyzJzbCAdS5Im1THQM3MXcCGwHtgCrM3MTRGxOiKWDbpBSVJ35nYzKTPXAevaxi6bYu4ZzduSJM2UnxSVpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCdBXoEbE0IrZGxHhErJpk+8cjYnNEbIyIb0TECf1vVZI0nY6BHhFzgKuAM4HFwIqIWNw27T5gJDN/EbgJuLLfjUqSptfNEfoSYDwzt2Xmi8ANwPLWCZl5R2Y+X6/eDSzob5uSpE66CfT5wPaW9R312FTOB25p0pQkaebm9rNYRHwIGAFOn2L7SmAlwPHHH9/PXUvSa143R+g7gYUt6wvqsVeJiHcDlwLLMvPHkxXKzDWZOZKZI0NDQ730K0maQjeBvgFYFBEnRsRBwLnAaOuEiHgH8HdUYf5k/9uUJHXSMdAzcxdwIbAe2AKszcxNEbE6IpbV0/4COBS4MSLuj4jRKcpJkgakq3PombkOWNc2dlnL8rv73JckaYb8pKgkFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQnQV6BGxNCK2RsR4RKyaZPvBEfGP9fZ7ImK4341KkqbXMdAjYg5wFXAmsBhYERGL26adDzyTmW8B/gr4dL8blSRNr5sj9CXAeGZuy8wXgRuA5W1zlgN/Xy/fBLwrIqJ/bUqSOonMnH5CxDnA0sz87Xr9N4FTMvPCljkP1nN21OsP13Oeaqu1ElhZr/4MsLXLPucBT3Wc1ZtB1Z5tdQdZ27qDrz3b6g6y9myrO9PaJ2Tm0GQb5vavn84ycw2wZqb3i4ixzBwZQEsDqz3b6g6ytnUHX3u21R1k7dlWt5+1uznlshNY2LK+oB6bdE5EzAWOAJ5u2pwkqXvdBPoGYFFEnBgRBwHnAqNtc0aBj9TL5wC3Z6dzOZKkvup4yiUzd0XEhcB6YA7wpczcFBGrgbHMHAW+CFwbEePAD6lCv59mfJpmP6g92+oOsrZ1B197ttUdZO3ZVrdvtTu+KSpJmh38pKgkFcJAl6RCGOiSVIi9eh16tyLirVSfPp1fD+0ERjNzy77ranp1z/OBezLzf1vGl2bm1xvUXQJkZm6ov3JhKfBQZq5r3PSr93NNZn64nzXruu+k+rTxg5l5a4M6pwBbMvO5iHgdsAo4GdgM/FlmPttj3YuAr2bm9l57m6Lu7ivCvp+Zt0XEB4FfBrYAazLzpYb13wx8gOpy4ZeB7wLXZeZzzTrXbLbfvSkaEZ8EVlB9xcCOengB1S/HDZl5xYD2e15mfrnH+14EfIzql/XtwMWZ+S/1tm9n5sk91r2c6jt05gL/DpwC3AG8B1ifmX/aY932y04D+BXgdoDMXNZL3br2f2Xmknr5AqrH5avAe4F/7fXnFxGbgLfVV12tAZ6n/pqJevwDPdZ9FvgR8DBwPXBjZk70Uqut7leofm6HAP8DHAr8c91vZOZHprl7p9oXAb8G3AWcBdxX7+PXgd/JzDsbNa+9LiKOyswnGxfKzP3qRnWkceAk4wcB3xvgfh9vcN/vAIfWy8PAGFWoA9zXsO4cqlB4Dji8Hn8dsLFB3W8D/wCcAZxe//uDevn0ho/jfS3LG4Chevn1wHca1N3S2n/btvub9Et16vG9VJffTgBfp/pcxWEN6m6s/50LPAHMqdejyc+u9XlRLx8C3FkvH9/k+VbXOAK4AniI6hLkp6kOVK4AjmxSe5p93tLgvocDfw5cC3ywbdtnG/Z1DPA5qi8nfBPwqfqxXwsc26DuG9tubwIeBd4AvLFJz/vjKZefAMcBj7WNH1tv61lEbJxqE3B0g9IHZH2aJTMfjYgzgJsi4oS6dq92ZebLwPMR8XDWL6cz84WIaPJYjAAXA5cCn8jM+yPihcz8ZoOaux0QEW+gCsnI+mg3M38UEbsa1H2w5VXUAxExkpljEXES0OT0RWbmT4BbgVsj4kCqV0UrgL8EJv3OjC4cUJ92eT1V6B5BFZAHAwc26He3uVSnWg6mOvonMx+v+29iLdUrtTMy878BIuIYqj9wa6n+8M1YREz1KjWoXtX26svA94B/An4rIs6mCvYfA6c2qAtwNXAz1c/wDuArVK+I3g98nj2/pLBbT7Fnvs2nOtBK4M091t0vj9CXAuPALVQX26+hOmIap/oCsCa1n6B68pzQdhumOtfZa93bgbe3jc0FrgFeblD3HuCQevmAlvEjaDtK7bH+AuBG4G9p8AqlreajwDbgkfrfY+vxQ2l2JH0E1S/Yw/Xj8lJd/5tUp1x6rTvlEe3ux77Hur9X9/cYcBHwDeALVEd4lzd8jC8GNtb1HgLOq8eHgLsa1t7ay7Yu6r5c/57cMcnthQZ1729bvxT4FtVRb6PfEV79avPx6fY7w7qX1Jn2Cy1jjzTp9ZU6/SjS7xvV0d2pwNn17VTql5gN634ReOcU265rUHcBcMwU205rUPfgKcbntT4Z+vC4vI/qjcVB/kwPAU7sQ53DgbcBvwQc3Yd6Jw3w/3wccFy9fCTV12Is6VPtn6vrvbXPPd8K/H7rY0v16vWTwG0N6j4ILJpi2/YGdbfQcrBTj30U2AQ81vCxeKBl+U/atvV8+rC+/+6Dqc8AhwHb+vHz2+/eFJW079Sny1ZRnU44qh5+gur7mq7IzGd6rHsOVQju8ZXZEfH+zPxaj3WvBG7NzNvaxpcCf5OZi3qpW9dYDVyZLVet1eNvoXoszum1dkutZcAfAsOZeUzjega6pG40uRKspLr9rl1fhvvTmflg07oGuqSuRMTjmXn8a73uIGs3rbs/XuUiaR8Z1JVgs63uIGsPsmcDXVKro4FfBdrPlQfwH6+huoOsPbCeDXRJrf6N6kNy97dviIg7X0N1B1l7YD17Dl2SCuG3LUpSIQx0SSqEgS5JhTDQJakQBrokFeL/AVBY8OoTc0rkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DataFrame(all_results)['mean'].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier   : mean  0.98, std 0.016\n",
      "LogisticRegression     : mean  0.96, std 0.039\n",
      "DecisionTreeClassifier : mean  0.96, std 0.033\n",
      "SVC                    : mean 0.9667, std 0.021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, KFold, StratifiedKFold, LeaveOneOut\n",
    "\n",
    "strategy = StratifiedKFold()\n",
    "\n",
    "iris = load_iris()\n",
    "X = DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = Series(iris.target)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "lr = LogisticRegression(solver='liblinear')  \n",
    "dtc = DecisionTreeClassifier()\n",
    "svc = SVC()\n",
    "\n",
    "for model in [knn, lr, dtc, svc]:\n",
    "    results = cross_val_score(model, X, y, cv=strategy)\n",
    "    print(f'{model.__class__.__name__:23}: mean {results.mean():5.4}, std {results.std():5.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'n_neighbors': range(1, 24, 2)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004544</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.004544      0.000768         0.005111        0.001272   \n",
       "1       0.002896      0.000132         0.004367        0.000454   \n",
       "2       0.003333      0.000535         0.004877        0.000536   \n",
       "3       0.002918      0.000329         0.004354        0.000309   \n",
       "4       0.002989      0.000422         0.004189        0.000258   \n",
       "\n",
       "  param_n_neighbors              params  split0_test_score  split1_test_score  \\\n",
       "0                 1  {'n_neighbors': 1}           0.966667           0.966667   \n",
       "1                 3  {'n_neighbors': 3}           0.966667           0.966667   \n",
       "2                 5  {'n_neighbors': 5}           0.966667           1.000000   \n",
       "3                 7  {'n_neighbors': 7}           0.966667           1.000000   \n",
       "4                 9  {'n_neighbors': 9}           0.966667           1.000000   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "0           0.933333           0.933333                1.0         0.960000   \n",
       "1           0.933333           0.966667                1.0         0.966667   \n",
       "2           0.933333           0.966667                1.0         0.973333   \n",
       "3           0.966667           0.966667                1.0         0.980000   \n",
       "4           0.966667           0.933333                1.0         0.973333   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.024944               11  \n",
       "1        0.021082                6  \n",
       "2        0.024944                3  \n",
       "3        0.016330                1  \n",
       "4        0.024944                3  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame(gs.cv_results_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>11</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.004085</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>13</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.029814</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002879</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.004502</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>17</td>\n",
       "      <td>{'n_neighbors': 17}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.029814</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>19</td>\n",
       "      <td>{'n_neighbors': 19}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.029814</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>21</td>\n",
       "      <td>{'n_neighbors': 21}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.029814</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004544</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>23</td>\n",
       "      <td>{'n_neighbors': 23}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3        0.002918      0.000329         0.004354        0.000309   \n",
       "5        0.002778      0.000250         0.004379        0.000340   \n",
       "2        0.003333      0.000535         0.004877        0.000536   \n",
       "4        0.002989      0.000422         0.004189        0.000258   \n",
       "6        0.002756      0.000205         0.004085        0.000151   \n",
       "1        0.002896      0.000132         0.004367        0.000454   \n",
       "7        0.002871      0.000268         0.004213        0.000391   \n",
       "8        0.002879      0.000271         0.004502        0.000381   \n",
       "9        0.002940      0.000199         0.004202        0.000149   \n",
       "10       0.003065      0.000313         0.004773        0.000396   \n",
       "0        0.004544      0.000768         0.005111        0.001272   \n",
       "11       0.003033      0.000276         0.004719        0.000759   \n",
       "\n",
       "   param_n_neighbors               params  split0_test_score  \\\n",
       "3                  7   {'n_neighbors': 7}           0.966667   \n",
       "5                 11  {'n_neighbors': 11}           0.933333   \n",
       "2                  5   {'n_neighbors': 5}           0.966667   \n",
       "4                  9   {'n_neighbors': 9}           0.966667   \n",
       "6                 13  {'n_neighbors': 13}           0.933333   \n",
       "1                  3   {'n_neighbors': 3}           0.966667   \n",
       "7                 15  {'n_neighbors': 15}           0.933333   \n",
       "8                 17  {'n_neighbors': 17}           0.933333   \n",
       "9                 19  {'n_neighbors': 19}           0.933333   \n",
       "10                21  {'n_neighbors': 21}           0.933333   \n",
       "0                  1   {'n_neighbors': 1}           0.966667   \n",
       "11                23  {'n_neighbors': 23}           0.933333   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "3            1.000000           0.966667           0.966667   \n",
       "5            1.000000           1.000000           0.966667   \n",
       "2            1.000000           0.933333           0.966667   \n",
       "4            1.000000           0.966667           0.933333   \n",
       "6            1.000000           0.966667           0.966667   \n",
       "1            0.966667           0.933333           0.966667   \n",
       "7            1.000000           0.933333           0.966667   \n",
       "8            1.000000           0.933333           0.966667   \n",
       "9            1.000000           0.933333           0.966667   \n",
       "10           1.000000           0.933333           0.966667   \n",
       "0            0.966667           0.933333           0.933333   \n",
       "11           1.000000           0.933333           0.933333   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "3                 1.0         0.980000        0.016330                1  \n",
       "5                 1.0         0.980000        0.026667                1  \n",
       "2                 1.0         0.973333        0.024944                3  \n",
       "4                 1.0         0.973333        0.024944                3  \n",
       "6                 1.0         0.973333        0.024944                3  \n",
       "1                 1.0         0.966667        0.021082                6  \n",
       "7                 1.0         0.966667        0.029814                6  \n",
       "8                 1.0         0.966667        0.029814                6  \n",
       "9                 1.0         0.966667        0.029814                6  \n",
       "10                1.0         0.966667        0.029814                6  \n",
       "0                 1.0         0.960000        0.024944               11  \n",
       "11                1.0         0.960000        0.032660               11  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier   : mean 0.9667, std  0.18\n",
      "LogisticRegression     : mean 0.9533, std  0.21\n",
      "DecisionTreeClassifier : mean 0.9467, std  0.22\n",
      "SVC                    : mean 0.9667, std  0.18\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, KFold, StratifiedKFold, LeaveOneOut\n",
    "\n",
    "strategy = LeaveOneOut()\n",
    "\n",
    "iris = load_iris()\n",
    "X = DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = Series(iris.target)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "lr = LogisticRegression(solver='liblinear')  \n",
    "dtc = DecisionTreeClassifier()\n",
    "svc = SVC()\n",
    "\n",
    "for model in [knn, lr, dtc, svc]:\n",
    "    results = cross_val_score(model, X, y, cv=strategy)\n",
    "    print(f'{model.__class__.__name__:23}: mean {results.mean():5.4}, std {results.std():5.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://archive.ics.uci.edu/ml/datasets/Wine\n",
    "    \n",
    "    # Goal: Predict grape type ('cultivar') from 13 variables used\n",
    "#  to measure wine.\n",
    "\n",
    "# The output/target/grape type is 1-2-3, in the first column of\n",
    "#  the data file (wine.data)\n",
    "\n",
    "# The other 13 columns in the file describe different variables\n",
    "#  that were measured.  (Look at the data dictionary/site to)\n",
    "#  see what those are.\n",
    "\n",
    "# You are to create a number of supervised classification models\n",
    "# to predict the grape type.  Use cross-validation and use a \n",
    "# test harness to compare the different types.\n",
    "\n",
    "# What model seems to predict the grapes best?\n",
    "\n",
    "# WARNING: Some models will be REALLY REALLY BAD at predicting.\n",
    "# Don't worry, that's normal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0       1    14.23        1.71  2.43               15.6        127   \n",
       "1       1    13.20        1.78  2.14               11.2        100   \n",
       "2       1    13.16        2.36  2.67               18.6        101   \n",
       "3       1    14.37        1.95  2.50               16.8        113   \n",
       "4       1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',\n",
    "                header=None,\n",
    "                names=['target', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis='columns')\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "DecisionTreeClassifier\n",
      "SVC\n",
      "LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "dtc = DecisionTreeClassifier()\n",
    "svc = SVC()\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "strategy = LeaveOneOut()\n",
    "\n",
    "all_results = []\n",
    "for model in [knn, dtc, svc, lr]:\n",
    "    print(model.__class__.__name__)\n",
    "    results = cross_val_score(model, X, y, cv=strategy)\n",
    "    all_results.append({'model':model.__class__.__name__,\n",
    "                        'mean':results.mean(),\n",
    "                        'std':results.std()})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.459714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.315808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.464359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.207181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model      mean       std\n",
       "0    KNeighborsClassifier  0.696629  0.459714\n",
       "1  DecisionTreeClassifier  0.887640  0.315808\n",
       "2                     SVC  0.685393  0.464359\n",
       "3      LogisticRegression  0.955056  0.207181"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x131000250>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium',\n",
       "       'Total phenols', 'Flavanoids', 'Nonflavanoid phenols',\n",
       "       'Proanthocyanins', 'Color intensity', 'Hue',\n",
       "       'OD280/OD315 of diluted wines', 'Proline'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "DecisionTreeClassifier\n",
      "SVC\n",
      "LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = df.drop(['target', 'Proline'], axis='columns')\n",
    "y = df['target']\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "dtc = DecisionTreeClassifier()\n",
    "svc = SVC()\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "strategy = LeaveOneOut()\n",
    "\n",
    "all_results = []\n",
    "for model in [knn, dtc, svc, lr]:\n",
    "    print(model.__class__.__name__)\n",
    "    results = cross_val_score(model, X, y, cv=strategy)\n",
    "    all_results.append({'model':model.__class__.__name__,\n",
    "                        'mean':results.mean(),\n",
    "                        'std':results.std()})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.364087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.932584</td>\n",
       "      <td>0.250741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.556180</td>\n",
       "      <td>0.496834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.926966</td>\n",
       "      <td>0.260192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model      mean       std\n",
       "0    KNeighborsClassifier  0.842697  0.364087\n",
       "1  DecisionTreeClassifier  0.932584  0.250741\n",
       "2                     SVC  0.556180  0.496834\n",
       "3      LogisticRegression  0.926966  0.260192"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#       KNeighborsClassifier \t0.696629 \t0.459714\n",
    "# 1 \tDecisionTreeClassifier \t0.887640 \t0.315808\n",
    "# 2 \tSVC \t0.685393 \t0.464359\n",
    "# 3 \tLogisticRegression \t0.955056 \t0.207181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "DecisionTreeClassifier\n",
      "SVC\n",
      "LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = df.drop('target', axis='columns')\n",
    "y = df['target']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)  # teach the scaler about min/max\n",
    "scaled_X = scaler.transform(X)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "dtc = DecisionTreeClassifier()\n",
    "svc = SVC()\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "strategy = LeaveOneOut()\n",
    "\n",
    "all_results = []\n",
    "for model in [knn, dtc, svc, lr]:\n",
    "    print(model.__class__.__name__)\n",
    "    results = cross_val_score(model, scaled_X, y, cv=strategy)\n",
    "    all_results.append({'model':model.__class__.__name__,\n",
    "                        'mean':results.mean(),\n",
    "                        'std':results.std()})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.949438</td>\n",
       "      <td>0.219101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.329120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.105403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.148212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model      mean       std\n",
       "0    KNeighborsClassifier  0.949438  0.219101\n",
       "1  DecisionTreeClassifier  0.876404  0.329120\n",
       "2                     SVC  0.988764  0.105403\n",
       "3      LogisticRegression  0.977528  0.148212"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression problems\n",
    "#  -- supervised learning\n",
    "#  -- output will be a floating-point number \n",
    "\n",
    "# Boston housing dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'filename', 'target']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'filename', 'target', 'target_names']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an X and y\n",
    "X = DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = Series(boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose an estimator + create a new model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with the model\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    506\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred == y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.894831181729202"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.52842291166747"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create an X and y\n",
    "X = DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = Series(boston.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# choose an estimator + create a new model\n",
    "model = LinearRegression()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     5.000000\n",
       "mean    -37.131807\n",
       "std      25.817580\n",
       "min     -80.762371\n",
       "25%     -33.313607\n",
       "50%     -33.074138\n",
       "75%     -26.048621\n",
       "max     -12.460301\n",
       "dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# create an X and y\n",
    "X = DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = Series(boston.target)\n",
    "\n",
    "# choose an estimator + create a new model\n",
    "model = LinearRegression()\n",
    "\n",
    "results = cross_val_score(model, X, y, cv=5,\n",
    "                          scoring='neg_mean_squared_error')\n",
    "Series(results).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
